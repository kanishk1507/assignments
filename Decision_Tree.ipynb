{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM8Je13JcC/2XCZrA96ZBk7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thepersonuadmire/Decision-Tree/blob/main/Decision_Tree.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Theoretical"
      ],
      "metadata": {
        "id": "me8MMNY9yqxW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. A Decision Tree is a flowchart-like structure used for decision-making and predictive modeling.\n",
        "\n",
        "It consists of nodes (representing features), branches (representing decision rules), and leaves (representing outcomes).\n",
        "The tree is built by splitting the dataset into subsets based on feature values, aiming to create homogeneous groups."
      ],
      "metadata": {
        "id": "UB-CY2_Cy5lu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Impurity measures quantify how mixed the classes are in a node.\n",
        "Common measures include Gini Impurity and Entropy."
      ],
      "metadata": {
        "id": "7RbB2ilWy56_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Gini Impurity = 1 - Σ(p_i^2)\n",
        "\n",
        "Where p_i is the probability of class i in the node."
      ],
      "metadata": {
        "id": "zzyYlLl8y6MO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Entropy = -Σ(p_i * log2(p_i))\n",
        "\n",
        "Where p_i is the probability of class i in the node."
      ],
      "metadata": {
        "id": "5hnHl2hNy6c8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Information Gain measures the reduction in entropy or impurity after a dataset is split on a feature.\n",
        "\n",
        "It is used to determine the best feature to split the data at each node."
      ],
      "metadata": {
        "id": "LKm7w-DPy6vL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.\n",
        "*   Gini Impurity focuses on the probability of misclassification, while\n",
        "Entropy measures the uncertainty in the dataset.\n",
        "*   Gini is generally faster to compute, while Entropy can provide more information in some cases."
      ],
      "metadata": {
        "id": "2jgS-tQ8y7Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Decision Trees use recursive partitioning based on impurity measures to create splits that maximize Information Gain."
      ],
      "metadata": {
        "id": "spJmo12Sy7Wv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Pre-Pruning involves stopping the tree growth early based on certain criteria (e.g., maximum depth, minimum samples per leaf) to prevent overfitting."
      ],
      "metadata": {
        "id": "qg3jZJd7y7uL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Post-Pruning involves removing branches from a fully grown tree to reduce complexity and improve generalization."
      ],
      "metadata": {
        "id": "e0Kjo1wWy79D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Pre-Pruning occurs during the tree construction, while Post-Pruning occurs after the tree is fully grown."
      ],
      "metadata": {
        "id": "h50yV2T5y8Y1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. A Decision Tree Regressor is a type of Decision Tree used for regression tasks, predicting continuous values instead of class labels."
      ],
      "metadata": {
        "id": "TDYOxxQgy8un"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12.\n",
        "1.   Advantages:\n",
        "\n",
        "*   Easy to interpret and visualize.\n",
        "*   Handles both numerical and categorical data.\n",
        "*   Requires little data preprocessing.\n",
        "\n",
        "2.   Disadvantages:\n",
        "\n",
        "*   Prone to overfitting.\n",
        "*   Sensitive to noisy data.\n",
        "*   Can be biased towards features with more levels."
      ],
      "metadata": {
        "id": "X3MCvsIgy9IR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. Decision Trees can handle missing values by using surrogate splits or by assigning the most common value for that feature."
      ],
      "metadata": {
        "id": "2E5WV-2Ty9Zl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. Decision Trees can directly handle categorical features by creating branches for each category."
      ],
      "metadata": {
        "id": "B2e7ahw3y9rx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. Medical diagnosis, Credit scoring, Customer segmentation, Fraud detection."
      ],
      "metadata": {
        "id": "QYsTKMo9y9-R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Practical"
      ],
      "metadata": {
        "id": "1-gFFgPfyw2u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16."
      ],
      "metadata": {
        "id": "tfqD-BEczXct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model\n",
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model Accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "lBOQMsoXzagZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "17."
      ],
      "metadata": {
        "id": "bYU8rN4tzbBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Train model with Gini Impurity\n",
        "clf = DecisionTreeClassifier(criterion='gini')\n",
        "clf.fit(X, y)\n",
        "\n",
        "# Print feature importances\n",
        "print(f'Feature Importances: {clf.feature_importances_}')"
      ],
      "metadata": {
        "id": "c57KaJexzb4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "18."
      ],
      "metadata": {
        "id": "tqTTNgIJzcFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load _iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model with Entropy\n",
        "clf = DecisionTreeClassifier(criterion='entropy')\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model Accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "f9ahQFZzzdLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "19."
      ],
      "metadata": {
        "id": "L9ThoAlTzdeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load housing dataset\n",
        "data = pd.read_csv('housing.csv')  # Replace with your dataset path\n",
        "X = data.drop('target', axis=1)  # Replace 'target' with your target column name\n",
        "y = data['target']\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model\n",
        "regressor = DecisionTreeRegressor()\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = regressor.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f'Mean Squared Error: {mse}')"
      ],
      "metadata": {
        "id": "WQtEn5LszejX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "20."
      ],
      "metadata": {
        "id": "sneSBw9Nze1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
        "import graphviz\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Train model\n",
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(X, y)\n",
        "\n",
        "# Visualize tree\n",
        "dot_data = export_graphviz(clf, out_file=None,\n",
        "                           feature_names=iris.feature_names,\n",
        "                           class_names=iris.target_names,\n",
        "                           filled=True, rounded=True,\n",
        "                           special_characters=True)\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph.render(\"iris_tree\")  # Save as iris_tree.pdf"
      ],
      "metadata": {
        "id": "eV9dHq5Hzgi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "21."
      ],
      "metadata": {
        "id": "15XvykLkzgIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train fully grown tree\n",
        "clf_full = DecisionTreeClassifier()\n",
        "clf_full.fit(X_train, y_train)\n",
        "y_pred_full = clf_full.predict(X_test)\n",
        "accuracy_full = accuracy_score(y_test, y_pred_full)\n",
        "\n",
        "# Train tree with max depth of 3\n",
        "clf_depth = DecisionTreeClassifier(max_depth=3)\n",
        "clf_depth.fit(X_train, y_train)\n",
        "y_pred_depth = clf_depth.predict(X_test)\n",
        "accuracy_depth = accuracy_score(y_test, y_pred_depth)\n",
        "\n",
        "print(f'Fully Grown Tree Accuracy: {accuracy_full}')\n",
        "print(f'Max Depth 3 Tree Accuracy: {accuracy_depth}')"
      ],
      "metadata": {
        "id": "F78Q9zq7ziVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "22."
      ],
      "metadata": {
        "id": "asdxCHTrzis9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train default tree\n",
        "clf_default = DecisionTreeClassifier()\n",
        "clf_default.fit(X_train, y_train)\n",
        "y_pred_default = clf_default.predict(X_test)\n",
        "accuracy_default = accuracy_score(y_test, y_pred_default)\n",
        "\n",
        "# Train tree with min_samples_split=5\n",
        "clf_split = DecisionTreeClassifier(min_samples_split=5)\n",
        "clf_split.fit(X_train, y_train)\n",
        "y_pred_split = clf_split.predict(X_test)\n",
        "accuracy_split = accuracy_score(y_test, y_pred_split)\n",
        "\n",
        "print(f'Default Tree Accuracy: {accuracy_default}')\n",
        "print(f'Min Samples Split Tree Accuracy: {accuracy_split}')"
      ],
      "metadata": {
        "id": "UxIueBTFzj5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "23."
      ],
      "metadata": {
        "id": "vU-8CvA_zkKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model without scaling\n",
        "clf_default = DecisionTreeClassifier()\n",
        "clf_default.fit(X_train, y_train)\n",
        "y_pred_default = clf_default.predict(X_test)\n",
        "accuracy_default = accuracy_score(y_test, y_pred_default)\n",
        "\n",
        "# Apply feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train model with scaling\n",
        "clf_scaled = DecisionTreeClassifier()\n",
        "clf_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = clf_scaled.predict(X_test_scaled)\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "print(f'Default Tree Accuracy: {accuracy_default}')\n",
        "print(f'Scaled Tree Accuracy: {accuracy_scaled}')"
      ],
      "metadata": {
        "id": "XxKBL-JlzlJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "24."
      ],
      "metadata": {
        "id": "IOB-igHQzlsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model using One-vs-Rest strategy\n",
        "clf_ovr = OneVsRestClassifier(DecisionTreeClassifier())\n",
        "clf_ovr.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred_ovr = clf_ovr.predict(X_test)\n",
        "accuracy_ovr = accuracy_score(y_test, y_pred_ovr)\n",
        "print(f'One-vs-Rest Tree Accuracy: {accuracy_ovr}')"
      ],
      "metadata": {
        "id": "_Qc2z7a2zm1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "25."
      ],
      "metadata": {
        "id": "TKT4_sTfznIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Train model\n",
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(X, y)\n",
        "\n",
        "# Display feature importance scores\n",
        "importance_scores = clf.feature_importances_\n",
        "for i, score in enumerate(importance_scores):\n",
        "    print(f'Feature {i}: Importance Score = {score}')"
      ],
      "metadata": {
        "id": "vEF3NdBTzqBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "26."
      ],
      "metadata": {
        "id": "6Dz559wCzqVi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load housing dataset\n",
        "data = pd.read_csv('housing.csv')  # Replace with your dataset path\n",
        "X = data.drop('target', axis=1)  # Replace 'target' with your target column name\n",
        "y = data['target']\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train unrestricted tree\n",
        "regressor_full = DecisionTreeRegressor()\n",
        "regressor_full.fit(X_train, y_train)\n",
        "y_pred_full = regressor_full.predict(X_test)\n",
        "mse_full = mean_squared_error(y_test, y_pred_full)\n",
        "\n",
        "# Train tree with max_depth=5\n",
        "regressor_depth = DecisionTreeRegressor(max_depth=5)\n",
        "regressor_depth.fit(X_train, y_train)\n",
        "y_pred_depth = regressor_depth.predict(X_test)\n",
        "mse_depth = mean_squared_error(y_test, y_pred_depth)\n",
        "\n",
        "print(f'Unrestricted Tree MSE: {mse_full}')\n",
        "print(f'Max Depth 5 Tree MSE: {mse_depth}')"
      ],
      "metadata": {
        "id": "EGrc_hFZzret"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "27."
      ],
      "metadata": {
        "id": "2fwOFw5Uzr1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model\n",
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict (X_test)\n",
        "accuracy_before_pruning = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Apply Cost Complexity Pruning\n",
        "path = clf.cost_complexity_pruning_path(X_train, y_train)\n",
        "ccp_alphas = path.ccp_alphas\n",
        "clfs = []\n",
        "\n",
        "for ccp_alpha in ccp_alphas:\n",
        "    clf = DecisionTreeClassifier(ccp_alpha=ccp_alpha)\n",
        "    clf.fit(X_train, y_train)\n",
        "    clfs.append(clf)\n",
        "\n",
        "# Evaluate accuracy for each pruned tree\n",
        "accuracies = [accuracy_score(y_test, clf.predict(X_test)) for clf in clfs]\n",
        "\n",
        "# Visualize effect on accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(ccp_alphas, accuracies, marker='o')\n",
        "plt.title('Effect of Cost Complexity Pruning on Accuracy')\n",
        "plt.xlabel('CCP Alpha')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "print(f'Accuracy before pruning: {accuracy_before_pruning}')"
      ],
      "metadata": {
        "id": "2dpq6woGzs3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "28."
      ],
      "metadata": {
        "id": "0PIH40TnztLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model\n",
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate Precision, Recall, and F1-Score\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1-Score: {f1}')"
      ],
      "metadata": {
        "id": "CzLjnjmszuOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "29."
      ],
      "metadata": {
        "id": "VgTWYv93zufP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model\n",
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Create confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Visualize confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=iris.target_names, yticklabels=iris.target_names)\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ciWg0dY5zvjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "30."
      ],
      "metadata": {
        "id": "9zzDV6WZzwzj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Set up the parameter grid\n",
        "param_grid = {\n",
        "    'max_depth': [None, 2, 3, 4, 5],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters and score\n",
        "print(f'Best Parameters: {grid_search.best_params_}')\n",
        "print(f'Best Cross-Validation Score: {grid_search.best_score_}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoknZIshzyA7",
        "outputId": "c8032604-cef1-408a-93ff-5277fe4c5e99"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': None, 'min_samples_split': 2}\n",
            "Best Cross-Validation Score: 0.95\n"
          ]
        }
      ]
    }
  ]
}